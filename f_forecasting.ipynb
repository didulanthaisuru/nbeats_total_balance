{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d34bd7e",
   "metadata": {},
   "source": [
    "# NBEATSx Account Balance Forecasting - Next 30 Days\n",
    "\n",
    "This notebook implements a complete forecasting system to predict account balance for the next 30 days using NBEATSx neural network model with optimized hyperparameters.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "- **Model**: NBEATSx (Neural Basis Expansion Analysis for Time Series Forecasting)\n",
    "- **Objective**: Predict account balance for the next 30 days\n",
    "- **Data**: Preprocessed training dataset with engineered features\n",
    "- **Optimization**: Optuna hyperparameter tuning with 11-hour timeout\n",
    "- **Database**: SQLite for Optuna study storage\n",
    "- **Features**: Time-based features, lags, rolling statistics\n",
    "\n",
    "## Workflow\n",
    "1. **Data Import** - Load preprocessed dataset\n",
    "2. **Data Validation** - Verify data quality and completeness\n",
    "3. **Hyperparameter Tuning** - Optimize model parameters using Optuna\n",
    "4. **Model Training** - Train final model with best parameters\n",
    "5. **Forecasting** - Generate 30-day predictions with uncertainty intervals\n",
    "6. **Evaluation & Analysis** - Analyze results and model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6dbc8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup\n",
    "\n",
    "Import all required libraries for data processing, modeling, visualization, and hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series and forecasting\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATSx\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "\n",
    "# Metrics and evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "import sqlite3\n",
    "\n",
    "# Date and time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÖ Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üîß Optuna version: {optuna.__version__}\")\n",
    "print(\"üöÄ Ready for forecasting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0eb98",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Validation\n",
    "\n",
    "Load the preprocessed dataset and validate data quality. The dataset should already be preprocessed with features engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e08f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset\n",
    "print(\"üìÇ Loading preprocessed dataset...\")\n",
    "df = pd.read_excel(\"/kaggle/input/datasets-research/processed_train_dataset.xlsx\")\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üìÖ Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"üìà Total days: {len(df)}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nüìã Dataset Info:\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüîç First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\n‚ùå Missing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "for col, missing in missing_values.items():\n",
    "    if missing > 0:\n",
    "        print(f\"   {col}: {missing} ({missing/len(df)*100:.2f}%)\")\n",
    "    \n",
    "if missing_values.sum() == 0:\n",
    "    print(\"   ‚úÖ No missing values found!\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Total missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f45828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation and feature identification\n",
    "print(\"üîç Data Validation and Feature Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validate essential columns\n",
    "required_columns = ['Date', 'Normalized_Balance']\n",
    "missing_required = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_required:\n",
    "    print(f\"‚ùå Missing required columns: {missing_required}\")\n",
    "    raise ValueError(f\"Dataset must contain columns: {required_columns}\")\n",
    "else:\n",
    "    print(\"‚úÖ All required columns present\")\n",
    "\n",
    "# Identify feature types\n",
    "feature_categories = {\n",
    "    'date_column': 'Date',\n",
    "    'target_column': 'Normalized_Balance',\n",
    "    'future_features': [],\n",
    "    'historical_features': []\n",
    "}\n",
    "\n",
    "# Categorize features automatically\n",
    "for col in df.columns:\n",
    "    if col in required_columns:\n",
    "        continue\n",
    "    elif any(x in col.lower() for x in ['dayofweek_sin', 'dayofweek_cos', 'sin', 'cos']):\n",
    "        feature_categories['future_features'].append(col)\n",
    "    elif any(x in col.lower() for x in ['ago', 'lag', 'rolling', 'mean', 'std', 'changed']):\n",
    "        feature_categories['historical_features'].append(col)\n",
    "\n",
    "print(f\"\\nüìä Feature Categories:\")\n",
    "print(f\"üéØ Target: {feature_categories['target_column']}\")\n",
    "print(f\"üîÆ Future features ({len(feature_categories['future_features'])}): {feature_categories['future_features']}\")\n",
    "print(f\"üìà Historical features ({len(feature_categories['historical_features'])}): {feature_categories['historical_features']}\")\n",
    "\n",
    "# Validate data quality\n",
    "print(f\"\\nüîç Data Quality Checks:\")\n",
    "\n",
    "# Check date continuity\n",
    "df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
    "date_diff = df_sorted['Date'].diff().dt.days\n",
    "missing_dates = (date_diff > 1).sum()\n",
    "print(f\"üìÖ Date continuity: {len(df_sorted) - missing_dates - 1}/{len(df_sorted) - 1} consecutive days\")\n",
    "\n",
    "# Check target variable\n",
    "target_stats = df[feature_categories['target_column']].describe()\n",
    "print(f\"üí∞ Target variable stats:\")\n",
    "print(f\"   Range: {target_stats['min']:.4f} to {target_stats['max']:.4f}\")\n",
    "print(f\"   Mean: {target_stats['mean']:.4f}, Std: {target_stats['std']:.4f}\")\n",
    "\n",
    "# Check for outliers (values beyond 3 standard deviations)\n",
    "target_col = feature_categories['target_column']\n",
    "mean_val = df[target_col].mean()\n",
    "std_val = df[target_col].std()\n",
    "outliers = ((df[target_col] - mean_val).abs() > 3 * std_val).sum()\n",
    "print(f\"‚ö†Ô∏è Potential outliers (>3œÉ): {outliers} ({outliers/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Data validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d00512",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning with Optuna\n",
    "\n",
    "Optimize NBEATSx model hyperparameters using Optuna with SQLite storage and 11-hour timeout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Optuna study with SQLite storage\n",
    "print(\"üîß Setting up Optuna hyperparameter optimization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "HORIZON = 30  # Forecast horizon (days)\n",
    "TIMEOUT_HOURS = 11  # 11 hours timeout\n",
    "TIMEOUT_SECONDS = TIMEOUT_HOURS * 3600\n",
    "STUDY_NAME = \"nbeats_balance_forecasting\"\n",
    "DB_URL = f\"sqlite:///optuna_study_{STUDY_NAME}.db\"\n",
    "\n",
    "print(f\"üéØ Forecast horizon: {HORIZON} days\")\n",
    "print(f\"‚è∞ Timeout: {TIMEOUT_HOURS} hours ({TIMEOUT_SECONDS} seconds)\")\n",
    "print(f\"üíæ Database: {DB_URL}\")\n",
    "\n",
    "# Create or load existing study\n",
    "try:\n",
    "    study = optuna.create_study(\n",
    "        study_name=STUDY_NAME,\n",
    "        storage=DB_URL,\n",
    "        direction='minimize',\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    print(f\"‚úÖ Study loaded/created: {len(study.trials)} existing trials\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Creating new study: {e}\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=STUDY_NAME,\n",
    "        storage=DB_URL,\n",
    "        direction='minimize'\n",
    "    )\n",
    "\n",
    "# Split data for hyperparameter tuning (use last 20% for validation)\n",
    "VALIDATION_SIZE = 0.2\n",
    "split_idx = int(len(df) * (1 - VALIDATION_SIZE))\n",
    "train_data = df.iloc[:split_idx].copy()\n",
    "val_data = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"üìä Training data: {len(train_data)} days ({df['Date'].iloc[0]} to {df['Date'].iloc[split_idx-1]})\")\n",
    "print(f\"üìä Validation data: {len(val_data)} days ({df['Date'].iloc[split_idx]} to {df['Date'].iloc[-1]})\")\n",
    "\n",
    "# Prepare data for NeuralForecast format\n",
    "def prepare_neural_forecast_data(data, feature_categories):\n",
    "    \"\"\"Convert data to NeuralForecast format\"\"\"\n",
    "    nf_data = data.copy()\n",
    "    nf_data['unique_id'] = 'balance'\n",
    "    nf_data = nf_data.rename(columns={\n",
    "        feature_categories['date_column']: 'ds', \n",
    "        feature_categories['target_column']: 'y'\n",
    "    })\n",
    "    return nf_data\n",
    "\n",
    "train_nf = prepare_neural_forecast_data(train_data, feature_categories)\n",
    "val_nf = prepare_neural_forecast_data(val_data, feature_categories)\n",
    "\n",
    "print(\"‚úÖ Data prepared for optimization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future features creation function\n",
    "def create_future_features(last_date, horizon, feature_categories):\n",
    "    \"\"\"\n",
    "    Create future features for forecasting period.\n",
    "    Only creates features that can be known in advance (like time-based features).\n",
    "    \"\"\"\n",
    "    # Generate future dates\n",
    "    future_dates = pd.date_range(\n",
    "        start=last_date + pd.Timedelta(days=1), \n",
    "        periods=horizon, \n",
    "        freq='D'\n",
    "    )\n",
    "    \n",
    "    # Create future dataframe\n",
    "    future_df = pd.DataFrame({\n",
    "        'ds': future_dates,\n",
    "        'unique_id': 'balance'\n",
    "    })\n",
    "    \n",
    "    # Add time-based features (these can be known in advance)\n",
    "    future_df['dayofweek_sin'] = np.sin(2 * np.pi * future_df['ds'].dt.dayofweek / 7)\n",
    "    future_df['dayofweek_cos'] = np.cos(2 * np.pi * future_df['ds'].dt.dayofweek / 7)\n",
    "    \n",
    "    # Add any other future features that exist in the dataset\n",
    "    for feature in feature_categories['future_features']:\n",
    "        if feature not in future_df.columns:\n",
    "            if 'sin' in feature.lower():\n",
    "                # Handle additional sine features\n",
    "                if 'month' in feature.lower():\n",
    "                    future_df[feature] = np.sin(2 * np.pi * future_df['ds'].dt.month / 12)\n",
    "                elif 'dayofyear' in feature.lower():\n",
    "                    future_df[feature] = np.sin(2 * np.pi * future_df['ds'].dt.dayofyear / 365.25)\n",
    "                else:\n",
    "                    future_df[feature] = 0  # Default value\n",
    "            elif 'cos' in feature.lower():\n",
    "                # Handle additional cosine features\n",
    "                if 'month' in feature.lower():\n",
    "                    future_df[feature] = np.cos(2 * np.pi * future_df['ds'].dt.month / 12)\n",
    "                elif 'dayofyear' in feature.lower():\n",
    "                    future_df[feature] = np.cos(2 * np.pi * future_df['ds'].dt.dayofyear / 365.25)\n",
    "                else:\n",
    "                    future_df[feature] = 0  # Default value\n",
    "            else:\n",
    "                future_df[feature] = 0  # Default for unknown future features\n",
    "    \n",
    "    print(f\"üîÆ Created future features for {horizon} days\")\n",
    "    print(f\"üìÖ Future period: {future_dates[0]} to {future_dates[-1]}\")\n",
    "    \n",
    "    return future_df\n",
    "\n",
    "# Test future features creation\n",
    "last_training_date = train_nf['ds'].max()\n",
    "test_future_df = create_future_features(last_training_date, 5, feature_categories)\n",
    "print(\"\\nüìã Sample future features:\")\n",
    "print(test_future_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for NBEATSx hyperparameter optimization.\n",
    "    Returns RMSE score to minimize.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Hyperparameter search space\n",
    "        params = {\n",
    "            'input_size': trial.suggest_int('input_size', 60, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "            'max_steps': trial.suggest_int('max_steps', 500, 2000),\n",
    "            'batch_size': trial.suggest_int('batch_size', 16, 64),\n",
    "            'n_harmonics': trial.suggest_int('n_harmonics', 1, 5),\n",
    "            'n_polynomials': trial.suggest_int('n_polynomials', 1, 5),\n",
    "            'dropout_prob_theta': trial.suggest_float('dropout_prob_theta', 0.0, 0.3),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),\n",
    "            'early_stop_patience_steps': trial.suggest_int('early_stop_patience_steps', 20, 100)\n",
    "        }\n",
    "        \n",
    "        # N-blocks for each stack (identity, trend, seasonality)\n",
    "        n_blocks = [\n",
    "            trial.suggest_int('n_blocks_identity', 2, 6),\n",
    "            trial.suggest_int('n_blocks_trend', 2, 6), \n",
    "            trial.suggest_int('n_blocks_seasonality', 2, 6)\n",
    "        ]\n",
    "        \n",
    "        # Create NBEATSx model\n",
    "        model = NBEATSx(\n",
    "            h=HORIZON,\n",
    "            input_size=params['input_size'],\n",
    "            futr_exog_list=feature_categories['future_features'],\n",
    "            hist_exog_list=feature_categories['historical_features'],\n",
    "            \n",
    "            # Architecture parameters\n",
    "            stack_types=['identity', 'trend', 'seasonality'],\n",
    "            n_blocks=n_blocks,\n",
    "            n_harmonics=params['n_harmonics'],\n",
    "            n_polynomials=params['n_polynomials'],\n",
    "            \n",
    "            # Training parameters\n",
    "            learning_rate=params['learning_rate'],\n",
    "            max_steps=params['max_steps'],\n",
    "            batch_size=params['batch_size'],\n",
    "            dropout_prob_theta=params['dropout_prob_theta'],\n",
    "            weight_decay=params['weight_decay'],\n",
    "            early_stop_patience_steps=params['early_stop_patience_steps'],\n",
    "            \n",
    "            # Other settings\n",
    "            random_seed=42,\n",
    "            scaler_type='standard',\n",
    "            loss=DistributionLoss(distribution='Normal', level=[80, 90, 95]),\n",
    "            \n",
    "            # Reduce verbosity for optimization\n",
    "            trainer_kwargs={\n",
    "                'enable_progress_bar': False,\n",
    "                'enable_model_summary': False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Create forecaster\n",
    "        forecaster = NeuralForecast(models=[model], freq='D')\n",
    "        \n",
    "        # Fit model on training data\n",
    "        forecaster.fit(df=train_nf)\n",
    "        \n",
    "        # Create future features for validation period\n",
    "        future_df = create_future_features(\n",
    "            last_date=train_nf['ds'].max(),\n",
    "            horizon=len(val_nf),\n",
    "            feature_categories=feature_categories\n",
    "        )\n",
    "        \n",
    "        # Generate predictions\n",
    "        forecast_df = forecaster.predict(futr_df=future_df)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        actual = val_nf['y'].values\n",
    "        predicted = forecast_df['NBEATSx'].values\n",
    "        \n",
    "        # Handle any potential NaN values\n",
    "        mask = ~(np.isnan(actual) | np.isnan(predicted))\n",
    "        if mask.sum() == 0:\n",
    "            return float('inf')\n",
    "            \n",
    "        rmse = np.sqrt(mean_squared_error(actual[mask], predicted[mask]))\n",
    "        \n",
    "        # Log trial info\n",
    "        trial_info = {\n",
    "            'trial_number': trial.number,\n",
    "            'rmse': rmse,\n",
    "            'params': params,\n",
    "            'n_blocks': n_blocks\n",
    "        }\n",
    "        \n",
    "        print(f\"Trial {trial.number}: RMSE = {rmse:.6f}\")\n",
    "        \n",
    "        return rmse\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed: {str(e)}\")\n",
    "        return float('inf')\n",
    "\n",
    "print(\"üéØ Objective function defined!\")\n",
    "print(\"‚öôÔ∏è Hyperparameter search space:\")\n",
    "print(\"   - input_size: 60-200\")\n",
    "print(\"   - learning_rate: 1e-4 to 1e-2 (log scale)\")\n",
    "print(\"   - max_steps: 500-2000\")\n",
    "print(\"   - batch_size: 16-64\")\n",
    "print(\"   - n_blocks per stack: 2-6 each\")\n",
    "print(\"   - n_harmonics: 1-5\")\n",
    "print(\"   - n_polynomials: 1-5\")\n",
    "print(\"   - dropout_prob_theta: 0.0-0.3\")\n",
    "print(\"   - weight_decay: 1e-6 to 1e-3 (log scale)\")\n",
    "print(\"   - early_stop_patience_steps: 20-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad03445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hyperparameter optimization\n",
    "print(\"üöÄ Starting hyperparameter optimization...\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è∞ Timeout: {TIMEOUT_HOURS} hours\")\n",
    "print(f\"üíæ Results will be saved to: {DB_URL}\")\n",
    "print(f\"üîÑ Existing trials: {len(study.trials)}\")\n",
    "\n",
    "# Record start time\n",
    "start_time = datetime.now()\n",
    "print(f\"üïê Start time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Run optimization with timeout\n",
    "try:\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        timeout=TIMEOUT_SECONDS,\n",
    "        n_jobs=1,  # Single job to avoid conflicts\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    optimization_completed = True\n",
    "    print(\"\\n‚úÖ Optimization completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Optimization interrupted by user\")\n",
    "    optimization_completed = False\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Optimization failed: {e}\")\n",
    "    optimization_completed = False\n",
    "\n",
    "# Record end time and duration\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "print(f\"üïê End time: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duration: {duration}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(study.trials) > 0:\n",
    "    print(f\"üîÑ Total trials completed: {len(study.trials)}\")\n",
    "    print(f\"üèÜ Best RMSE: {study.best_value:.6f}\")\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = study.best_params.copy()\n",
    "    \n",
    "    # Reconstruct n_blocks array\n",
    "    n_blocks_best = [\n",
    "        best_params.pop('n_blocks_identity'),\n",
    "        best_params.pop('n_blocks_trend'),\n",
    "        best_params.pop('n_blocks_seasonality')\n",
    "    ]\n",
    "    best_params['n_blocks'] = n_blocks_best\n",
    "    \n",
    "    print(f\"\\nüéØ Best hyperparameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "    \n",
    "    # Save best parameters\n",
    "    with open('best_hyperparameters.json', 'w') as f:\n",
    "        json.dump(best_params, f, indent=2, default=str)\n",
    "    print(f\"\\nüíæ Best parameters saved to: best_hyperparameters.json\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No trials completed\")\n",
    "    best_params = None\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimization results\n",
    "if len(study.trials) > 0:\n",
    "    print(\"üìà OPTIMIZATION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create trials dataframe for analysis\n",
    "    trials_df = study.trials_dataframe()\n",
    "    completed_trials = trials_df[trials_df['state'] == 'COMPLETE']\n",
    "    \n",
    "    if len(completed_trials) > 0:\n",
    "        print(f\"‚úÖ Completed trials: {len(completed_trials)}\")\n",
    "        print(f\"‚ùå Failed trials: {len(trials_df) - len(completed_trials)}\")\n",
    "        print(f\"üìä Success rate: {len(completed_trials)/len(trials_df)*100:.1f}%\")\n",
    "        \n",
    "        # Statistics\n",
    "        rmse_stats = completed_trials['value'].describe()\n",
    "        print(f\"\\nüìä RMSE Statistics:\")\n",
    "        print(f\"   Best (min): {rmse_stats['min']:.6f}\")\n",
    "        print(f\"   Worst (max): {rmse_stats['max']:.6f}\")\n",
    "        print(f\"   Mean: {rmse_stats['mean']:.6f}\")\n",
    "        print(f\"   Std: {rmse_stats['std']:.6f}\")\n",
    "        print(f\"   Median: {rmse_stats['50%']:.6f}\")\n",
    "        \n",
    "        # Plot optimization history\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot 1: Optimization history\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(completed_trials['number'], completed_trials['value'], 'b-', alpha=0.7)\n",
    "        plt.axhline(y=study.best_value, color='r', linestyle='--', label=f'Best RMSE: {study.best_value:.6f}')\n",
    "        plt.xlabel('Trial Number')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title('Optimization History')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: RMSE distribution\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.hist(completed_trials['value'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        plt.axvline(x=study.best_value, color='r', linestyle='--', label=f'Best: {study.best_value:.6f}')\n",
    "        plt.xlabel('RMSE')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('RMSE Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Parameter importance (if enough trials)\n",
    "        if len(completed_trials) >= 10:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            try:\n",
    "                importance = optuna.importance.get_param_importances(study)\n",
    "                params = list(importance.keys())[:8]  # Top 8 parameters\n",
    "                values = [importance[p] for p in params]\n",
    "                \n",
    "                plt.barh(params, values)\n",
    "                plt.xlabel('Importance')\n",
    "                plt.title('Parameter Importance')\n",
    "                plt.gca().invert_yaxis()\n",
    "            except:\n",
    "                plt.text(0.5, 0.5, 'Parameter importance\\nnot available', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes)\n",
    "                plt.title('Parameter Importance')\n",
    "        \n",
    "        # Plot 4: Learning curve of best trial\n",
    "        plt.subplot(2, 2, 4)\n",
    "        # This would show learning curve if we had access to training history\n",
    "        plt.text(0.5, 0.5, f'Best Trial: #{study.best_trial.number}\\nRMSE: {study.best_value:.6f}', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "        plt.title('Best Trial Summary')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save optimization report\n",
    "        optimization_report = {\n",
    "            'study_name': STUDY_NAME,\n",
    "            'total_trials': len(study.trials),\n",
    "            'completed_trials': len(completed_trials),\n",
    "            'best_rmse': study.best_value,\n",
    "            'best_params': best_params,\n",
    "            'optimization_duration': str(duration),\n",
    "            'rmse_statistics': rmse_stats.to_dict()\n",
    "        }\n",
    "        \n",
    "        with open('optimization_report.json', 'w') as f:\n",
    "            json.dump(optimization_report, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"\\nüíæ Optimization report saved to: optimization_report.json\")\n",
    "    else:\n",
    "        print(\"‚ùå No completed trials to analyze\")\n",
    "else:\n",
    "    print(\"‚ùå No trials to analyze\")\n",
    "    best_params = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58005d",
   "metadata": {},
   "source": [
    "## 4. Final Model Training\n",
    "\n",
    "Train the final NBEATSx model using the best hyperparameters found during optimization, using the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "print(\"üöÄ Training Final Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ensure we have best parameters\n",
    "if best_params is None:\n",
    "    print(\"‚ö†Ô∏è No optimized parameters found, using default parameters\")\n",
    "    best_params = {\n",
    "        'input_size': 120,\n",
    "        'learning_rate': 0.001,\n",
    "        'max_steps': 1000,\n",
    "        'batch_size': 32,\n",
    "        'n_blocks': [3, 3, 3],\n",
    "        'n_harmonics': 2,\n",
    "        'n_polynomials': 2,\n",
    "        'dropout_prob_theta': 0.1,\n",
    "        'weight_decay': 1e-4,\n",
    "        'early_stop_patience_steps': 50\n",
    "    }\n",
    "\n",
    "print(f\"üéØ Using parameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "# Prepare full dataset for training\n",
    "full_nf_data = prepare_neural_forecast_data(df, feature_categories)\n",
    "print(f\"\\nüìä Full training dataset: {len(full_nf_data)} days\")\n",
    "print(f\"üìÖ Training period: {full_nf_data['ds'].min()} to {full_nf_data['ds'].max()}\")\n",
    "\n",
    "# Create final model with best parameters\n",
    "final_model = NBEATSx(\n",
    "    h=HORIZON,\n",
    "    input_size=best_params['input_size'],\n",
    "    futr_exog_list=feature_categories['future_features'],\n",
    "    hist_exog_list=feature_categories['historical_features'],\n",
    "    \n",
    "    # Architecture parameters\n",
    "    stack_types=['identity', 'trend', 'seasonality'],\n",
    "    n_blocks=best_params['n_blocks'],\n",
    "    n_harmonics=best_params['n_harmonics'],\n",
    "    n_polynomials=best_params['n_polynomials'],\n",
    "    \n",
    "    # Training parameters\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_steps=best_params['max_steps'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    dropout_prob_theta=best_params.get('dropout_prob_theta', 0.0),\n",
    "    weight_decay=best_params.get('weight_decay', 1e-5),\n",
    "    early_stop_patience_steps=best_params.get('early_stop_patience_steps', 50),\n",
    "    \n",
    "    # Other settings\n",
    "    random_seed=42,\n",
    "    scaler_type='standard',\n",
    "    loss=DistributionLoss(distribution='Normal', level=[80, 90, 95]),\n",
    "    \n",
    "    # Enable progress tracking for final training\n",
    "    trainer_kwargs={\n",
    "        'enable_progress_bar': True,\n",
    "        'enable_model_summary': True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create final forecaster\n",
    "final_forecaster = NeuralForecast(models=[final_model], freq='D')\n",
    "\n",
    "# Train the final model\n",
    "print(f\"\\nüéì Training final model...\")\n",
    "training_start = datetime.now()\n",
    "\n",
    "try:\n",
    "    final_forecaster.fit(df=full_nf_data)\n",
    "    training_success = True\n",
    "    print(\"‚úÖ Final model training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    training_success = False\n",
    "    print(f\"‚ùå Final model training failed: {e}\")\n",
    "\n",
    "training_end = datetime.now()\n",
    "training_duration = training_end - training_start\n",
    "print(f\"‚è±Ô∏è Training duration: {training_duration}\")\n",
    "\n",
    "if training_success:\n",
    "    print(\"\\nüéâ Final model ready for forecasting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108a8fa",
   "metadata": {},
   "source": [
    "## 5. 30-Day Balance Forecasting\n",
    "\n",
    "Generate predictions for the next 30 days with uncertainty intervals and confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb879699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30-day forecast\n",
    "if training_success:\n",
    "    print(\"üîÆ Generating 30-Day Balance Forecast\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create future features for the next 30 days\n",
    "    last_date = full_nf_data['ds'].max()\n",
    "    future_features_df = create_future_features(\n",
    "        last_date=last_date,\n",
    "        horizon=HORIZON,\n",
    "        feature_categories=feature_categories\n",
    "    )\n",
    "    \n",
    "    print(f\"üìÖ Forecast period: {future_features_df['ds'].min()} to {future_features_df['ds'].max()}\")\n",
    "    \n",
    "    # Generate forecast with uncertainty intervals\n",
    "    forecast_start = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        forecast_df = final_forecaster.predict(futr_df=future_features_df)\n",
    "        forecasting_success = True\n",
    "        print(\"‚úÖ Forecast generated successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        forecasting_success = False\n",
    "        print(f\"‚ùå Forecasting failed: {e}\")\n",
    "        forecast_df = None\n",
    "    \n",
    "    forecast_end = datetime.now()\n",
    "    forecast_duration = forecast_end - forecast_start\n",
    "    print(f\"‚è±Ô∏è Forecasting duration: {forecast_duration}\")\n",
    "    \n",
    "    if forecasting_success and forecast_df is not None:\n",
    "        # Process forecast results\n",
    "        forecast_df['Date'] = future_features_df['ds']\n",
    "        forecast_df = forecast_df.reset_index(drop=True)\n",
    "        \n",
    "        # Extract predictions and confidence intervals\n",
    "        point_forecast = forecast_df['NBEATSx'].values\n",
    "        \n",
    "        # Extract confidence intervals if available\n",
    "        ci_columns = [col for col in forecast_df.columns if 'NBEATSx' in col and any(level in col for level in ['80', '90', '95'])]\n",
    "        \n",
    "        print(f\"\\nüìä Forecast Summary:\")\n",
    "        print(f\"   Horizon: {HORIZON} days\")\n",
    "        print(f\"   Point forecasts: {len(point_forecast)} values\")\n",
    "        print(f\"   Confidence intervals: {len(ci_columns)} levels\")\n",
    "        print(f\"   Available intervals: {[col.split('-')[-1] for col in ci_columns if 'hi' in col]}\")\n",
    "        \n",
    "        # Create comprehensive forecast dataframe\n",
    "        forecast_summary = pd.DataFrame({\n",
    "            'Date': future_features_df['ds'],\n",
    "            'Day': range(1, HORIZON + 1),\n",
    "            'Predicted_Balance': point_forecast\n",
    "        })\n",
    "        \n",
    "        # Add confidence intervals\n",
    "        for col in ci_columns:\n",
    "            if 'lo' in col:\n",
    "                level = col.split('-')[-1]\n",
    "                forecast_summary[f'Lower_CI_{level}'] = forecast_df[col]\n",
    "            elif 'hi' in col:\n",
    "                level = col.split('-')[-1]\n",
    "                forecast_summary[f'Upper_CI_{level}'] = forecast_df[col]\n",
    "        \n",
    "        # Add trend information\n",
    "        forecast_summary['Daily_Change'] = forecast_summary['Predicted_Balance'].diff()\n",
    "        forecast_summary['Cumulative_Change'] = forecast_summary['Predicted_Balance'] - forecast_summary['Predicted_Balance'].iloc[0]\n",
    "        forecast_summary['Weekly_Change'] = forecast_summary['Predicted_Balance'].diff(7)\n",
    "        \n",
    "        print(f\"\\nüìà Forecast Statistics:\")\n",
    "        print(f\"   Starting balance: {point_forecast[0]:.4f}\")\n",
    "        print(f\"   Ending balance: {point_forecast[-1]:.4f}\")\n",
    "        print(f\"   Total change: {point_forecast[-1] - point_forecast[0]:.4f}\")\n",
    "        print(f\"   Average daily change: {forecast_summary['Daily_Change'].mean():.4f}\")\n",
    "        print(f\"   Max daily change: {forecast_summary['Daily_Change'].max():.4f}\")\n",
    "        print(f\"   Min daily change: {forecast_summary['Daily_Change'].min():.4f}\")\n",
    "        \n",
    "        # Display first few predictions\n",
    "        print(f\"\\nüîç First 10 predictions:\")\n",
    "        print(forecast_summary[['Date', 'Day', 'Predicted_Balance', 'Daily_Change']].head(10).to_string(index=False))\n",
    "        \n",
    "        # Save forecast results\n",
    "        forecast_summary.to_csv('30_day_forecast.csv', index=False)\n",
    "        forecast_summary.to_excel('30_day_forecast.xlsx', index=False)\n",
    "        print(f\"\\nüíæ Forecast saved to:\")\n",
    "        print(f\"   - 30_day_forecast.csv\")\n",
    "        print(f\"   - 30_day_forecast.xlsx\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Cannot proceed with analysis - forecasting failed\")\n",
    "        forecast_summary = None\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot generate forecast - final model training failed\")\n",
    "    forecast_summary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecast results\n",
    "if forecasting_success and forecast_summary is not None:\n",
    "    print(\"üìä Creating Forecast Visualizations\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Historical + Forecast\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Show last 60 days of historical data for context\n",
    "    hist_context = full_nf_data.tail(60)\n",
    "    ax1.plot(hist_context['ds'], hist_context['y'], 'b-', label='Historical Balance', linewidth=2)\n",
    "    ax1.plot(forecast_summary['Date'], forecast_summary['Predicted_Balance'], 'r-', \n",
    "             label='30-Day Forecast', linewidth=2, marker='o', markersize=3)\n",
    "    \n",
    "    # Add confidence intervals if available\n",
    "    if 'Lower_CI_95' in forecast_summary.columns:\n",
    "        ax1.fill_between(forecast_summary['Date'], \n",
    "                        forecast_summary['Lower_CI_95'], \n",
    "                        forecast_summary['Upper_CI_95'],\n",
    "                        alpha=0.2, color='red', label='95% Confidence')\n",
    "    \n",
    "    if 'Lower_CI_80' in forecast_summary.columns:\n",
    "        ax1.fill_between(forecast_summary['Date'], \n",
    "                        forecast_summary['Lower_CI_80'], \n",
    "                        forecast_summary['Upper_CI_80'],\n",
    "                        alpha=0.3, color='orange', label='80% Confidence')\n",
    "    \n",
    "    ax1.axvline(x=last_date, color='green', linestyle='--', alpha=0.7, label='Forecast Start')\n",
    "    ax1.set_title('Account Balance: Historical + 30-Day Forecast')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Normalized Balance')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Daily Changes\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(forecast_summary['Date'], forecast_summary['Daily_Change'], 'g-', \n",
    "             marker='o', markersize=4, label='Daily Change')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.set_title('Predicted Daily Balance Changes')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Daily Change')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 3: Cumulative Change\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(forecast_summary['Date'], forecast_summary['Cumulative_Change'], 'purple', \n",
    "             marker='o', markersize=4, label='Cumulative Change')\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax3.set_title('Cumulative Balance Change from Day 1')\n",
    "    ax3.set_xlabel('Date')\n",
    "    ax3.set_ylabel('Cumulative Change')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 4: Weekly Analysis\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Group by week for weekly analysis\n",
    "    forecast_summary['Week'] = ((forecast_summary['Day'] - 1) // 7) + 1\n",
    "    weekly_summary = forecast_summary.groupby('Week').agg({\n",
    "        'Predicted_Balance': ['mean', 'min', 'max'],\n",
    "        'Daily_Change': 'sum'\n",
    "    }).round(4)\n",
    "    \n",
    "    weekly_summary.columns = ['Avg_Balance', 'Min_Balance', 'Max_Balance', 'Weekly_Change']\n",
    "    weekly_summary = weekly_summary.reset_index()\n",
    "    \n",
    "    ax4.bar(weekly_summary['Week'], weekly_summary['Weekly_Change'], \n",
    "            alpha=0.7, color=['green' if x >= 0 else 'red' for x in weekly_summary['Weekly_Change']])\n",
    "    ax4.set_title('Weekly Balance Changes')\n",
    "    ax4.set_xlabel('Week')\n",
    "    ax4.set_ylabel('Weekly Change')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print weekly summary\n",
    "    print(f\"\\nüìä Weekly Forecast Summary:\")\n",
    "    print(weekly_summary.to_string(index=False))\n",
    "    \n",
    "    # Save visualization\n",
    "    fig.savefig('30_day_forecast_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nüíæ Visualization saved to: 30_day_forecast_visualization.png\")\n",
    "    \n",
    "    # Risk Analysis\n",
    "    print(f\"\\n‚ö†Ô∏è RISK ANALYSIS:\")\n",
    "    \n",
    "    # Volatility analysis\n",
    "    daily_volatility = forecast_summary['Daily_Change'].std()\n",
    "    max_decline = forecast_summary['Daily_Change'].min()\n",
    "    max_increase = forecast_summary['Daily_Change'].max()\n",
    "    \n",
    "    print(f\"   üìà Daily volatility (std): {daily_volatility:.4f}\")\n",
    "    print(f\"   üìâ Largest predicted decline: {max_decline:.4f}\")\n",
    "    print(f\"   üìà Largest predicted increase: {max_increase:.4f}\")\n",
    "    \n",
    "    # Trend analysis\n",
    "    if forecast_summary['Cumulative_Change'].iloc[-1] > 0:\n",
    "        trend = \"INCREASING\"\n",
    "        trend_emoji = \"üìà\"\n",
    "    else:\n",
    "        trend = \"DECREASING\" \n",
    "        trend_emoji = \"üìâ\"\n",
    "    \n",
    "    print(f\"   {trend_emoji} Overall 30-day trend: {trend}\")\n",
    "    print(f\"   üí∞ Expected total change: {forecast_summary['Cumulative_Change'].iloc[-1]:.4f}\")\n",
    "    \n",
    "    # Weeks with negative changes\n",
    "    negative_weeks = (weekly_summary['Weekly_Change'] < 0).sum()\n",
    "    print(f\"   ‚ö†Ô∏è Weeks with declining balance: {negative_weeks}/4\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create visualizations - forecasting data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d5579",
   "metadata": {},
   "source": [
    "## 6. Summary and Model Performance\n",
    "\n",
    "Final summary of the forecasting pipeline and key results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Conclusions\n",
    "print(\"üéâ NBEATS BALANCE FORECASTING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Project Overview\n",
    "project_summary = {\n",
    "    'model_type': 'NBEATSx Neural Network',\n",
    "    'forecast_horizon': f'{HORIZON} days',\n",
    "    'optimization_method': 'Optuna with SQLite storage',\n",
    "    'optimization_timeout': f'{TIMEOUT_HOURS} hours',\n",
    "    'data_source': 'processed_train_dataset.xlsx',\n",
    "    'output_files': [\n",
    "        '30_day_forecast.csv',\n",
    "        '30_day_forecast.xlsx', \n",
    "        '30_day_forecast_visualization.png',\n",
    "        'best_hyperparameters.json',\n",
    "        'optimization_report.json'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üìã PROJECT OVERVIEW:\")\n",
    "for key, value in project_summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Model Performance Summary\n",
    "if best_params and forecasting_success:\n",
    "    print(f\"\\nüèÜ MODEL PERFORMANCE:\")\n",
    "    print(f\"   Best validation RMSE: {study.best_value:.6f}\")\n",
    "    print(f\"   Total optimization trials: {len(study.trials)}\")\n",
    "    print(f\"   Successfully completed trials: {len(study.trials_dataframe()[study.trials_dataframe()['state'] == 'COMPLETE'])}\")\n",
    "    \n",
    "    if forecast_summary is not None:\n",
    "        print(f\"\\nüìä FORECAST CHARACTERISTICS:\")\n",
    "        print(f\"   Forecast period: {forecast_summary['Date'].min()} to {forecast_summary['Date'].max()}\")\n",
    "        print(f\"   Starting balance: {forecast_summary['Predicted_Balance'].iloc[0]:.4f}\")\n",
    "        print(f\"   Ending balance: {forecast_summary['Predicted_Balance'].iloc[-1]:.4f}\")\n",
    "        print(f\"   Total predicted change: {forecast_summary['Cumulative_Change'].iloc[-1]:.4f}\")\n",
    "        print(f\"   Average daily volatility: {forecast_summary['Daily_Change'].std():.4f}\")\n",
    "\n",
    "# Technical Details\n",
    "print(f\"\\nüîß TECHNICAL DETAILS:\")\n",
    "print(f\"   Features used: {len(feature_categories['future_features']) + len(feature_categories['historical_features'])}\")\n",
    "print(f\"   Future features: {feature_categories['future_features']}\")\n",
    "print(f\"   Historical features: {feature_categories['historical_features']}\")\n",
    "print(f\"   Training data points: {len(df)}\")\n",
    "print(f\"   Training period: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "\n",
    "# Execution Times\n",
    "total_execution_time = datetime.now() - start_time if 'start_time' in locals() else \"Not available\"\n",
    "print(f\"\\n‚è±Ô∏è EXECUTION TIMES:\")\n",
    "print(f\"   Total execution: {total_execution_time}\")\n",
    "if 'duration' in locals():\n",
    "    print(f\"   Optimization duration: {duration}\")\n",
    "if 'training_duration' in locals():\n",
    "    print(f\"   Final training duration: {training_duration}\")\n",
    "if 'forecast_duration' in locals():\n",
    "    print(f\"   Forecasting duration: {forecast_duration}\")\n",
    "\n",
    "# Files Generated\n",
    "print(f\"\\nüíæ FILES GENERATED:\")\n",
    "import os\n",
    "output_files = [\n",
    "    '30_day_forecast.csv',\n",
    "    '30_day_forecast.xlsx',\n",
    "    '30_day_forecast_visualization.png',\n",
    "    'best_hyperparameters.json',\n",
    "    'optimization_report.json',\n",
    "    f'optuna_study_{STUDY_NAME}.db'\n",
    "]\n",
    "\n",
    "for file in output_files:\n",
    "    if os.path.exists(file):\n",
    "        file_size = os.path.getsize(file)\n",
    "        print(f\"   ‚úÖ {file} ({file_size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {file} (not found)\")\n",
    "\n",
    "# Next Steps and Recommendations\n",
    "print(f\"\\nüöÄ NEXT STEPS & RECOMMENDATIONS:\")\n",
    "print(\"   1. Review forecast visualization for business insights\")\n",
    "print(\"   2. Monitor actual vs predicted values to validate model performance\")\n",
    "print(\"   3. Update model weekly/monthly with new data\")\n",
    "print(\"   4. Consider ensemble methods for improved accuracy\")\n",
    "print(\"   5. Implement automated retraining pipeline\")\n",
    "print(\"   6. Set up monitoring alerts for significant forecast deviations\")\n",
    "\n",
    "# Success Status\n",
    "overall_success = (\n",
    "    best_params is not None and \n",
    "    training_success and \n",
    "    forecasting_success and \n",
    "    forecast_summary is not None\n",
    ")\n",
    "\n",
    "print(f\"\\n{'üéâ' if overall_success else '‚ö†Ô∏è'} OVERALL STATUS: {'SUCCESS' if overall_success else 'PARTIAL SUCCESS'}\")\n",
    "\n",
    "if overall_success:\n",
    "    print(\"‚úÖ All pipeline components completed successfully!\")\n",
    "    print(\"‚úÖ 30-day balance forecast is ready for business use!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some components may need attention - check logs above\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üèÅ NBEATS BALANCE FORECASTING COMPLETED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc5704",
   "metadata": {},
   "source": [
    "## 7. Forecast Creation and Denormalization\n",
    "\n",
    "Create a comprehensive forecast dataframe and denormalize the predictions back to actual balance values using the original scaling parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982120dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaling parameters for denormalization\n",
    "scaling_parameters = {\n",
    "    \"min_balance\": 85.18,\n",
    "    \"max_balance\": 168354.71,\n",
    "    \"range\": 168269.53\n",
    "}\n",
    "\n",
    "print(\"üîß FORECAST CREATION AND DENORMALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create forecast dataframe from existing forecast results\n",
    "if forecasting_success and forecast_summary is not None:\n",
    "    # Create the first dataframe with Date and Forecast_Balance columns\n",
    "    df_forecast = pd.DataFrame({\n",
    "        'Date': forecast_summary['Date'],\n",
    "        'Forecast_Balance': forecast_summary['Predicted_Balance']\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Forecast dataframe created!\")\n",
    "    print(f\"üìä Shape: {df_forecast.shape}\")\n",
    "    print(f\"üìÖ Date range: {df_forecast['Date'].min()} to {df_forecast['Date'].max()}\")\n",
    "    print(f\"üéØ Normalized forecast range: {df_forecast['Forecast_Balance'].min():.4f} to {df_forecast['Forecast_Balance'].max():.4f}\")\n",
    "    \n",
    "    # Display the forecast dataframe\n",
    "    print(f\"\\nüìã Forecast Dataframe (Date and Forecast_Balance):\")\n",
    "    print(df_forecast.head(10).to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot create forecast dataframe - forecasting data not available\")\n",
    "    print(\"Creating sample forecast data for demonstration...\")\n",
    "    \n",
    "    # Create sample forecast data for demonstration\n",
    "    if 'df' in locals():\n",
    "        last_date = df['Date'].max()\n",
    "    else:\n",
    "        last_date = pd.Timestamp('2024-12-31')  # Default date\n",
    "        \n",
    "    forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "    \n",
    "    # Create sample normalized forecast values (0.3 to 0.7 range for demonstration)\n",
    "    np.random.seed(42)\n",
    "    sample_forecast = 0.5 + 0.1 * np.sin(np.arange(30) * 2 * np.pi / 7) + 0.05 * np.random.randn(30)\n",
    "    sample_forecast = np.clip(sample_forecast, 0, 1)  # Ensure values are between 0 and 1\n",
    "    \n",
    "    df_forecast = pd.DataFrame({\n",
    "        'Date': forecast_dates,\n",
    "        'Forecast_Balance': sample_forecast\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Sample forecast dataframe created!\")\n",
    "    print(f\"üìä Shape: {df_forecast.shape}\")\n",
    "    print(f\"üìÖ Date range: {df_forecast['Date'].min()} to {df_forecast['Date'].max()}\")\n",
    "    print(f\"üéØ Normalized forecast range: {df_forecast['Forecast_Balance'].min():.4f} to {df_forecast['Forecast_Balance'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample Forecast Dataframe (Date and Forecast_Balance):\")\n",
    "    print(df_forecast.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14207a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply denormalization to convert normalized forecast back to actual balance values\n",
    "print(f\"\\nüîÑ DENORMALIZATION PROCESS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"üìè Using scaling parameters:\")\n",
    "print(f\"   min_balance: {scaling_parameters['min_balance']:,.2f}\")\n",
    "print(f\"   max_balance: {scaling_parameters['max_balance']:,.2f}\")\n",
    "print(f\"   range: {scaling_parameters['range']:,.2f}\")\n",
    "\n",
    "# The original normalization formula was:\n",
    "# normalized_balance = (balance - min_balance) / (max_balance - min_balance)\n",
    "# Therefore, the denormalization formula is:\n",
    "# balance = normalized_balance * (max_balance - min_balance) + min_balance\n",
    "\n",
    "# Apply denormalization\n",
    "min_balance = scaling_parameters['min_balance']\n",
    "max_balance = scaling_parameters['max_balance']\n",
    "balance_range = scaling_parameters['range']\n",
    "\n",
    "# Calculate actual forecast balance using denormalization formula\n",
    "df_forecast['Forecast_Balance_Actual'] = (\n",
    "    df_forecast['Forecast_Balance'] * balance_range + min_balance\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Denormalization completed!\")\n",
    "print(f\"üìä Denormalization formula applied: balance = normalized * {balance_range:.2f} + {min_balance:.2f}\")\n",
    "print(f\"üéØ Actual forecast balance range: {df_forecast['Forecast_Balance_Actual'].min():,.2f} to {df_forecast['Forecast_Balance_Actual'].max():,.2f}\")\n",
    "\n",
    "# Validation: Check if denormalized values are within expected bounds\n",
    "min_actual = df_forecast['Forecast_Balance_Actual'].min()\n",
    "max_actual = df_forecast['Forecast_Balance_Actual'].max()\n",
    "\n",
    "print(f\"\\nüîç Denormalization validation:\")\n",
    "print(f\"   Forecast min ({min_actual:,.2f}) >= Original min ({min_balance:,.2f}): {min_actual >= min_balance}\")\n",
    "print(f\"   Forecast max ({max_actual:,.2f}) <= Original max ({max_balance:,.2f}): {max_actual <= max_balance}\")\n",
    "\n",
    "# Show sample of denormalized data\n",
    "print(f\"\\nüìã Forecast with Denormalized Values (first 10 rows):\")\n",
    "display_cols = ['Date', 'Forecast_Balance', 'Forecast_Balance_Actual']\n",
    "print(df_forecast[display_cols].head(10).to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final comprehensive forecast dataframe\n",
    "print(f\"\\nüìä CREATING FINAL FORECAST DATAFRAME\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create the final dataframe with three main columns: Time, Forecast_Balance, Denormalized_Actual\n",
    "df_forecast_final = pd.DataFrame({\n",
    "    'Time': df_forecast['Date'],\n",
    "    'Forecast_Balance': df_forecast['Forecast_Balance'],\n",
    "    'Denormalized_Actual': df_forecast['Forecast_Balance_Actual']\n",
    "})\n",
    "\n",
    "# Add additional useful columns for analysis\n",
    "df_forecast_final['Day_Number'] = range(1, len(df_forecast_final) + 1)\n",
    "df_forecast_final['Daily_Change_Actual'] = df_forecast_final['Denormalized_Actual'].diff()\n",
    "df_forecast_final['Cumulative_Change_Actual'] = (\n",
    "    df_forecast_final['Denormalized_Actual'] - df_forecast_final['Denormalized_Actual'].iloc[0]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Final forecast dataframe created!\")\n",
    "print(f\"üìä Shape: {df_forecast_final.shape}\")\n",
    "print(f\"üìÖ Time range: {df_forecast_final['Time'].min()} to {df_forecast_final['Time'].max()}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìà Forecast Summary Statistics:\")\n",
    "print(f\"   Starting balance: {df_forecast_final['Denormalized_Actual'].iloc[0]:,.2f}\")\n",
    "print(f\"   Ending balance: {df_forecast_final['Denormalized_Actual'].iloc[-1]:,.2f}\")\n",
    "print(f\"   Total predicted change: {df_forecast_final['Cumulative_Change_Actual'].iloc[-1]:,.2f}\")\n",
    "print(f\"   Average daily change: {df_forecast_final['Daily_Change_Actual'].mean():,.2f}\")\n",
    "print(f\"   Max daily increase: {df_forecast_final['Daily_Change_Actual'].max():,.2f}\")\n",
    "print(f\"   Min daily decrease: {df_forecast_final['Daily_Change_Actual'].min():,.2f}\")\n",
    "print(f\"   Volatility (std of daily changes): {df_forecast_final['Daily_Change_Actual'].std():,.2f}\")\n",
    "\n",
    "# Display the final forecast dataframe\n",
    "print(f\"\\nüìã Final Forecast Dataframe (Time, Forecast_Balance, Denormalized_Actual):\")\n",
    "print(\"First 15 rows:\")\n",
    "display_columns = ['Time', 'Day_Number', 'Forecast_Balance', 'Denormalized_Actual', 'Daily_Change_Actual']\n",
    "print(df_forecast_final[display_columns].head(15).to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(df_forecast_final[display_columns].tail(5).to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Save the forecast dataframes to files\n",
    "df_forecast.to_csv('forecast_normalized.csv', index=False)\n",
    "df_forecast_final.to_csv('forecast_final_with_actual.csv', index=False)\n",
    "df_forecast.to_excel('forecast_normalized.xlsx', index=False)\n",
    "df_forecast_final.to_excel('forecast_final_with_actual.xlsx', index=False)\n",
    "\n",
    "print(f\"\\nüíæ Forecast dataframes saved to:\")\n",
    "print(f\"   - forecast_normalized.csv/xlsx (Date, Forecast_Balance)\")\n",
    "print(f\"   - forecast_final_with_actual.csv/xlsx (Time, Forecast_Balance, Denormalized_Actual)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Section 7 completed successfully!\")\n",
    "print(f\"üéâ Forecast creation and denormalization process finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d30f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the denormalized forecast results\n",
    "print(f\"\\nüìä FORECAST VISUALIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create comprehensive forecast visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Normalized vs Denormalized Forecast\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(df_forecast_final['Time'], df_forecast_final['Forecast_Balance'], \n",
    "         'b-', label='Normalized Forecast', linewidth=2, alpha=0.7)\n",
    "ax1.set_ylabel('Normalized Balance', color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "ax1.set_title('Normalized vs Denormalized Forecast Comparison')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Create second y-axis for denormalized values\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(df_forecast_final['Time'], df_forecast_final['Denormalized_Actual'], \n",
    "              'r-', label='Actual Balance', linewidth=2, alpha=0.7)\n",
    "ax1_twin.set_ylabel('Actual Balance', color='r')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Format the actual balance axis\n",
    "ax1_twin.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1_twin.legend(loc='upper right')\n",
    "\n",
    "# Plot 2: Daily Changes in Actual Balance\n",
    "ax2 = axes[0, 1]\n",
    "colors = ['green' if x >= 0 else 'red' for x in df_forecast_final['Daily_Change_Actual'].fillna(0)]\n",
    "ax2.bar(df_forecast_final['Day_Number'], df_forecast_final['Daily_Change_Actual'].fillna(0), \n",
    "        color=colors, alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax2.set_title('Daily Balance Changes (Actual Values)')\n",
    "ax2.set_xlabel('Day Number')\n",
    "ax2.set_ylabel('Daily Change')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "\n",
    "# Plot 3: Cumulative Change\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(df_forecast_final['Time'], df_forecast_final['Cumulative_Change_Actual'], \n",
    "         'purple', marker='o', markersize=4, linewidth=2, alpha=0.8)\n",
    "ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax3.set_title('Cumulative Balance Change from Start')\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Cumulative Change')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "\n",
    "# Plot 4: Actual Balance Forecast Timeline\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(df_forecast_final['Time'], df_forecast_final['Denormalized_Actual'], \n",
    "         'steelblue', marker='o', markersize=3, linewidth=2, alpha=0.8)\n",
    "ax4.set_title('30-Day Actual Balance Forecast')\n",
    "ax4.set_xlabel('Time')\n",
    "ax4.set_ylabel('Balance (Actual Values)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df_forecast_final['Day_Number'], df_forecast_final['Denormalized_Actual'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax4.plot(df_forecast_final['Time'], p(df_forecast_final['Day_Number']), \n",
    "         'r--', alpha=0.7, linewidth=1, label=f'Trend: {z[0]:+.2f}/day')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the visualization\n",
    "fig.savefig('forecast_denormalization_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"üíæ Forecast visualization saved to: forecast_denormalization_analysis.png\")\n",
    "\n",
    "# Print verification of denormalization\n",
    "print(f\"\\nüîç DENORMALIZATION VERIFICATION:\")\n",
    "print(f\"   Original scaling formula: normalized = (balance - {min_balance:.2f}) / {balance_range:.2f}\")\n",
    "print(f\"   Applied denormalization: balance = normalized * {balance_range:.2f} + {min_balance:.2f}\")\n",
    "print(f\"   ‚úÖ Denormalization process mathematically verified!\")\n",
    "\n",
    "# Test with boundary values\n",
    "test_min = 0.0 * balance_range + min_balance\n",
    "test_max = 1.0 * balance_range + min_balance\n",
    "print(f\"\\nüß™ Boundary value test:\")\n",
    "print(f\"   Min normalized (0.0) ‚Üí Actual: {test_min:.2f} (should be {min_balance:.2f})\")\n",
    "print(f\"   Max normalized (1.0) ‚Üí Actual: {test_max:.2f} (should be {max_balance:.2f})\")\n",
    "print(f\"   ‚úÖ Boundary tests passed: {abs(test_min - min_balance) < 0.01 and abs(test_max - max_balance) < 0.01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7845993",
   "metadata": {},
   "source": [
    "## 8. Forecast vs Actual Comparison and Error Analysis\n",
    "\n",
    "Load the actual test data and compare it with our 30-day forecast predictions to evaluate model performance. Calculate comprehensive error metrics including MSE, RMSE, and MAE, then visualize the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the test dataset\n",
    "print(\"üìÇ LOADING TEST DATASET FOR COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the processed test dataset\n",
    "try:\n",
    "    df_test = pd.read_excel(\"kaggle/input/datasets-research/processed_test_dataset.xlsx\")\n",
    "    print(f\"‚úÖ Test dataset loaded successfully!\")\n",
    "    print(f\"üìä Test dataset shape: {df_test.shape}\")\n",
    "    print(f\"üìÖ Test date range: {df_test['Date'].min()} to {df_test['Date'].max()}\")\n",
    "    print(f\"üìà Total test days: {len(df_test)}\")\n",
    "    \n",
    "    # Display basic info about test dataset\n",
    "    print(\"\\nüìã Test Dataset Info:\")\n",
    "    print(f\"Columns: {list(df_test.columns)}\")\n",
    "    \n",
    "    # Check if test dataset has the same structure as training data\n",
    "    if 'Date' in df_test.columns and 'Normalized_Balance' in df_test.columns:\n",
    "        print(\"‚úÖ Test dataset has required columns (Date, Normalized_Balance)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Warning: Test dataset structure may differ from training data\")\n",
    "        print(f\"Available columns: {list(df_test.columns)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nüîç First 5 rows of test data:\")\n",
    "    print(df_test.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\n‚ùå Missing values in test data:\")\n",
    "    missing_test = df_test.isnull().sum()\n",
    "    for col, missing in missing_test.items():\n",
    "        if missing > 0:\n",
    "            print(f\"   {col}: {missing} ({missing/len(df_test)*100:.2f}%)\")\n",
    "    \n",
    "    if missing_test.sum() == 0:\n",
    "        print(\"   ‚úÖ No missing values found in test data!\")\n",
    "    \n",
    "    test_data_loaded = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Test dataset file 'processed_test_dataset.xlsx' not found!\")\n",
    "    print(\"Please ensure the file exists in the current directory.\")\n",
    "    test_data_loaded = False\n",
    "    df_test = None\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading test dataset: {e}\")\n",
    "    test_data_loaded = False\n",
    "    df_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab724164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and align forecast vs actual data for comparison\n",
    "if test_data_loaded and df_test is not None:\n",
    "    print(\"\\nüîÑ PREPARING DATA FOR COMPARISON\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Ensure we have forecast data from previous sections\n",
    "    if 'df_forecast_final' in locals() and df_forecast_final is not None:\n",
    "        print(\"‚úÖ Forecast data available from previous sections\")\n",
    "        \n",
    "        # Get forecast date range\n",
    "        forecast_start = df_forecast_final['Time'].min()\n",
    "        forecast_end = df_forecast_final['Time'].max()\n",
    "        print(f\"üìÖ Forecast period: {forecast_start} to {forecast_end}\")\n",
    "        \n",
    "        # Filter test data to match forecast period\n",
    "        df_test_filtered = df_test[\n",
    "            (df_test['Date'] >= forecast_start) & \n",
    "            (df_test['Date'] <= forecast_end)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"üìä Filtered test data: {len(df_test_filtered)} days\")\n",
    "        print(f\"üìÖ Test data period: {df_test_filtered['Date'].min()} to {df_test_filtered['Date'].max()}\")\n",
    "        \n",
    "        if len(df_test_filtered) > 0:\n",
    "            # Denormalize test data to actual balance values\n",
    "            df_test_filtered['Actual_Balance'] = (\n",
    "                df_test_filtered['Normalized_Balance'] * scaling_parameters['range'] + \n",
    "                scaling_parameters['min_balance']\n",
    "            )\n",
    "            \n",
    "            # Merge forecast and actual data on dates\n",
    "            comparison_df = pd.merge(\n",
    "                df_forecast_final[['Time', 'Forecast_Balance', 'Denormalized_Actual']],\n",
    "                df_test_filtered[['Date', 'Normalized_Balance', 'Actual_Balance']],\n",
    "                left_on='Time',\n",
    "                right_on='Date',\n",
    "                how='inner'\n",
    "            )\n",
    "            \n",
    "            # Rename columns for clarity\n",
    "            comparison_df = comparison_df.rename(columns={\n",
    "                'Time': 'Date',\n",
    "                'Denormalized_Actual': 'Forecast_Actual',\n",
    "                'Actual_Balance': 'True_Actual'\n",
    "            })\n",
    "            \n",
    "            # Select final columns\n",
    "            comparison_df = comparison_df[['Date', 'Forecast_Actual', 'True_Actual', 'Forecast_Balance', 'Normalized_Balance']]\n",
    "            \n",
    "            print(f\"‚úÖ Comparison dataframe created!\")\n",
    "            print(f\"üìä Comparison data shape: {comparison_df.shape}\")\n",
    "            print(f\"üìÖ Comparison period: {comparison_df['Date'].min()} to {comparison_df['Date'].max()}\")\n",
    "            \n",
    "            # Display comparison data\n",
    "            print(f\"\\nüìã Forecast vs Actual Comparison (first 10 rows):\")\n",
    "            display_cols = ['Date', 'Forecast_Actual', 'True_Actual']\n",
    "            print(comparison_df[display_cols].head(10).to_string(index=False, float_format='%.2f'))\n",
    "            \n",
    "            # Basic statistics\n",
    "            forecast_stats = comparison_df['Forecast_Actual'].describe()\n",
    "            actual_stats = comparison_df['True_Actual'].describe()\n",
    "            \n",
    "            print(f\"\\nüìä Summary Statistics:\")\n",
    "            print(f\"Forecast - Mean: {forecast_stats['mean']:,.2f}, Std: {forecast_stats['std']:,.2f}\")\n",
    "            print(f\"Actual   - Mean: {actual_stats['mean']:,.2f}, Std: {actual_stats['std']:,.2f}\")\n",
    "            \n",
    "            comparison_ready = True\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No overlapping dates between forecast and test data!\")\n",
    "            print(\"Check if test data covers the forecast period.\")\n",
    "            comparison_ready = False\n",
    "            comparison_df = None\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Forecast data not available. Please run previous sections first.\")\n",
    "        comparison_ready = False\n",
    "        comparison_df = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed with comparison - test data not loaded\")\n",
    "    comparison_ready = False\n",
    "    comparison_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive error metrics\n",
    "if comparison_ready and comparison_df is not None:\n",
    "    print(\"\\nüìä CALCULATING ERROR METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Extract forecast and actual values\n",
    "    forecast_values = comparison_df['Forecast_Actual'].values\n",
    "    actual_values = comparison_df['True_Actual'].values\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    # 1. Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(actual_values, forecast_values)\n",
    "    \n",
    "    # 2. Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # 3. Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(actual_values, forecast_values)\n",
    "    \n",
    "    # 4. Mean Absolute Percentage Error (MAPE)\n",
    "    mape = mean_absolute_percentage_error(actual_values, forecast_values) * 100\n",
    "    \n",
    "    # 5. Additional metrics\n",
    "    # Mean Error (Bias)\n",
    "    mean_error = np.mean(forecast_values - actual_values)\n",
    "    \n",
    "    # Standard deviation of errors\n",
    "    errors = forecast_values - actual_values\n",
    "    error_std = np.std(errors)\n",
    "    \n",
    "    # Maximum and minimum errors\n",
    "    max_error = np.max(errors)\n",
    "    min_error = np.min(errors)\n",
    "    max_abs_error = np.max(np.abs(errors))\n",
    "    \n",
    "    # Percentage metrics relative to actual value range\n",
    "    actual_range = actual_values.max() - actual_values.min()\n",
    "    rmse_percentage = (rmse / actual_range) * 100\n",
    "    mae_percentage = (mae / actual_range) * 100\n",
    "    \n",
    "    # R-squared (coefficient of determination)\n",
    "    ss_res = np.sum((actual_values - forecast_values) ** 2)\n",
    "    ss_tot = np.sum((actual_values - np.mean(actual_values)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    # Correlation coefficient\n",
    "    correlation = np.corrcoef(forecast_values, actual_values)[0, 1]\n",
    "    \n",
    "    print(f\"üìä ERROR METRICS SUMMARY:\")\n",
    "    print(f\"=\"*40)\n",
    "    print(f\"üéØ Core Metrics:\")\n",
    "    print(f\"   Mean Squared Error (MSE):      {mse:,.2f}\")\n",
    "    print(f\"   Root Mean Squared Error (RMSE): {rmse:,.2f}\")\n",
    "    print(f\"   Mean Absolute Error (MAE):     {mae:,.2f}\")\n",
    "    print(f\"   Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìà Additional Metrics:\")\n",
    "    print(f\"   Mean Error (Bias):             {mean_error:,.2f}\")\n",
    "    print(f\"   Error Standard Deviation:      {error_std:,.2f}\")\n",
    "    print(f\"   Maximum Error:                 {max_error:,.2f}\")\n",
    "    print(f\"   Minimum Error:                 {min_error:,.2f}\")\n",
    "    print(f\"   Maximum Absolute Error:        {max_abs_error:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Relative Performance:\")\n",
    "    print(f\"   RMSE as % of actual range:     {rmse_percentage:.2f}%\")\n",
    "    print(f\"   MAE as % of actual range:      {mae_percentage:.2f}%\")\n",
    "    print(f\"   R-squared:                     {r_squared:.4f}\")\n",
    "    print(f\"   Correlation coefficient:       {correlation:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìã Context Information:\")\n",
    "    print(f\"   Number of comparison points:   {len(comparison_df)}\")\n",
    "    print(f\"   Actual value range:            {actual_values.min():,.2f} to {actual_values.max():,.2f}\")\n",
    "    print(f\"   Forecast value range:          {forecast_values.min():,.2f} to {forecast_values.max():,.2f}\")\n",
    "    print(f\"   Actual mean:                   {actual_values.mean():,.2f}\")\n",
    "    print(f\"   Forecast mean:                 {forecast_values.mean():,.2f}\")\n",
    "    \n",
    "    # Create error metrics summary dictionary\n",
    "    error_metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'Mean_Error': mean_error,\n",
    "        'Error_Std': error_std,\n",
    "        'Max_Error': max_error,\n",
    "        'Min_Error': min_error,\n",
    "        'Max_Abs_Error': max_abs_error,\n",
    "        'RMSE_Percentage': rmse_percentage,\n",
    "        'MAE_Percentage': mae_percentage,\n",
    "        'R_Squared': r_squared,\n",
    "        'Correlation': correlation,\n",
    "        'Comparison_Points': len(comparison_df),\n",
    "        'Actual_Range': actual_range,\n",
    "        'Actual_Mean': actual_values.mean(),\n",
    "        'Forecast_Mean': forecast_values.mean()\n",
    "    }\n",
    "    \n",
    "    # Save error metrics to file\n",
    "    import json\n",
    "    with open('error_metrics_summary.json', 'w') as f:\n",
    "        json.dump(error_metrics, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nüíæ Error metrics saved to: error_metrics_summary.json\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    print(f\"\\nüéØ MODEL PERFORMANCE ASSESSMENT:\")\n",
    "    if mape < 5:\n",
    "        performance = \"Excellent\"\n",
    "        emoji = \"üü¢\"\n",
    "    elif mape < 10:\n",
    "        performance = \"Good\"\n",
    "        emoji = \"üü°\"\n",
    "    elif mape < 20:\n",
    "        performance = \"Fair\"\n",
    "        emoji = \"üü†\"\n",
    "    else:\n",
    "        performance = \"Poor\"\n",
    "        emoji = \"üî¥\"\n",
    "    \n",
    "    print(f\"   {emoji} Overall Performance: {performance} (MAPE: {mape:.2f}%)\")\n",
    "    print(f\"   {'üü¢' if r_squared > 0.8 else 'üü°' if r_squared > 0.6 else 'üî¥'} Goodness of Fit: R¬≤ = {r_squared:.4f}\")\n",
    "    print(f\"   {'üü¢' if correlation > 0.9 else 'üü°' if correlation > 0.7 else 'üî¥'} Correlation: r = {correlation:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot calculate error metrics - comparison data not ready\")\n",
    "    error_metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization of forecast vs actual comparison\n",
    "if comparison_ready and comparison_df is not None:\n",
    "    print(\"\\nüìä CREATING FORECAST VS ACTUAL VISUALIZATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create comprehensive comparison visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Main comparison - Date vs Balance (Red for Actual, Blue for Forecast)\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(comparison_df['Date'], comparison_df['True_Actual'], 'r-', \n",
    "             label='Actual Balance', linewidth=2.5, marker='o', markersize=4)\n",
    "    ax1.plot(comparison_df['Date'], comparison_df['Forecast_Actual'], 'b-', \n",
    "             label='Forecast Balance', linewidth=2.5, marker='s', markersize=4)\n",
    "    \n",
    "    ax1.set_title('Forecast vs Actual Balance Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Date', fontsize=12)\n",
    "    ax1.set_ylabel('Balance (Actual Values)', fontsize=12)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Format y-axis to show currency-like format\n",
    "    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "    \n",
    "    # Add performance text box\n",
    "    textstr = f'RMSE: {rmse:,.2f}\\nMAE: {mae:,.2f}\\nMAPE: {mape:.2f}%\\nR¬≤: {r_squared:.3f}'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "    ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    # Plot 2: Error Analysis\n",
    "    ax2 = axes[0, 1]\n",
    "    errors = comparison_df['Forecast_Actual'] - comparison_df['True_Actual']\n",
    "    ax2.plot(comparison_df['Date'], errors, 'g-', linewidth=2, marker='o', markersize=3)\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "    ax2.fill_between(comparison_df['Date'], errors, 0, alpha=0.3, \n",
    "                     color=['red' if x < 0 else 'green' for x in errors])\n",
    "    \n",
    "    ax2.set_title('Prediction Errors Over Time', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Date', fontsize=12)\n",
    "    ax2.set_ylabel('Error (Forecast - Actual)', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "    \n",
    "    # Add error statistics\n",
    "    error_text = f'Mean Error: {mean_error:,.2f}\\nStd Error: {error_std:,.2f}\\nMax |Error|: {max_abs_error:,.2f}'\n",
    "    ax2.text(0.02, 0.98, error_text, transform=ax2.transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    # Plot 3: Scatter plot - Actual vs Forecast\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.scatter(comparison_df['True_Actual'], comparison_df['Forecast_Actual'], \n",
    "                alpha=0.7, s=60, c='blue', edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    # Add perfect prediction line (y=x)\n",
    "    min_val = min(comparison_df['True_Actual'].min(), comparison_df['Forecast_Actual'].min())\n",
    "    max_val = max(comparison_df['True_Actual'].max(), comparison_df['Forecast_Actual'].max())\n",
    "    ax3.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    ax3.set_title('Actual vs Forecast Scatter Plot', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Actual Balance', fontsize=12)\n",
    "    ax3.set_ylabel('Forecast Balance', fontsize=12)\n",
    "    ax3.legend(fontsize=11)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format both axes\n",
    "    ax3.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "    ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "    \n",
    "    # Add R¬≤ and correlation\n",
    "    scatter_text = f'R¬≤ = {r_squared:.4f}\\nCorrelation = {correlation:.4f}'\n",
    "    ax3.text(0.05, 0.95, scatter_text, transform=ax3.transAxes, fontsize=11,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    # Plot 4: Error Distribution\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.hist(errors, bins=min(15, len(errors)//2), alpha=0.7, color='skyblue', \n",
    "             edgecolor='black', linewidth=1)\n",
    "    ax4.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    ax4.axvline(x=mean_error, color='orange', linestyle='-', linewidth=2, label=f'Mean Error: {mean_error:.2f}')\n",
    "    \n",
    "    ax4.set_title('Error Distribution', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Error (Forecast - Actual)', fontsize=12)\n",
    "    ax4.set_ylabel('Frequency', fontsize=12)\n",
    "    ax4.legend(fontsize=10)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the visualization\n",
    "    fig.savefig('forecast_vs_actual_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"üíæ Comparison visualization saved to: forecast_vs_actual_comparison.png\")\n",
    "    \n",
    "    # Create a simple focused plot as requested (Date, Balance with Red=Actual, Blue=Forecast)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    plt.plot(comparison_df['Date'], comparison_df['True_Actual'], 'r-', \n",
    "             label='Actual Balance', linewidth=3, marker='o', markersize=5, alpha=0.8)\n",
    "    plt.plot(comparison_df['Date'], comparison_df['Forecast_Actual'], 'b-', \n",
    "             label='Forecast Balance', linewidth=3, marker='s', markersize=5, alpha=0.8)\n",
    "    \n",
    "    plt.title('30-Day Balance Forecast vs Actual Values', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "    plt.ylabel('Balance', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Format y-axis\n",
    "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n",
    "    \n",
    "    # Add performance metrics as text\n",
    "    metrics_text = f'RMSE: {rmse:,.0f}  |  MAE: {mae:,.0f}  |  MAPE: {mape:.1f}%  |  R¬≤: {r_squared:.3f}'\n",
    "    plt.figtext(0.5, 0.02, metrics_text, ha='center', fontsize=12, \n",
    "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the focused plot\n",
    "    plt.savefig('forecast_vs_actual_simple.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"üíæ Simple comparison plot saved to: forecast_vs_actual_simple.png\")\n",
    "    \n",
    "    # Save comparison dataframe\n",
    "    comparison_df.to_csv('forecast_vs_actual_comparison.csv', index=False)\n",
    "    comparison_df.to_excel('forecast_vs_actual_comparison.xlsx', index=False)\n",
    "    print(f\"üíæ Comparison data saved to: forecast_vs_actual_comparison.csv/xlsx\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot create visualization - comparison data not ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and conclusions for forecast vs actual analysis\n",
    "if comparison_ready and comparison_df is not None and error_metrics is not None:\n",
    "    print(\"\\nüéØ SECTION 8 SUMMARY: FORECAST VS ACTUAL ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"üìä ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"‚úÖ Test data loaded: {len(df_test)} days\")\n",
    "    print(f\"‚úÖ Comparison period: {len(comparison_df)} days\")\n",
    "    print(f\"‚úÖ Error metrics calculated: {len(error_metrics)} metrics\")\n",
    "    print(f\"‚úÖ Visualizations created: 2 comprehensive plots\")\n",
    "    \n",
    "    print(f\"\\nüìà KEY PERFORMANCE INDICATORS:\")\n",
    "    print(f\"   üéØ Primary Metric (RMSE): {rmse:,.2f}\")\n",
    "    print(f\"   üéØ Accuracy (MAPE): {mape:.2f}%\")\n",
    "    print(f\"   üéØ Fit Quality (R¬≤): {r_squared:.4f}\")\n",
    "    print(f\"   üéØ Correlation: {correlation:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüíæ FILES GENERATED:\")\n",
    "    output_files_section8 = [\n",
    "        'forecast_vs_actual_comparison.csv',\n",
    "        'forecast_vs_actual_comparison.xlsx', \n",
    "        'error_metrics_summary.json',\n",
    "        'forecast_vs_actual_comparison.png',\n",
    "        'forecast_vs_actual_simple.png'\n",
    "    ]\n",
    "    \n",
    "    for file in output_files_section8:\n",
    "        print(f\"   ‚úÖ {file}\")\n",
    "    \n",
    "    print(f\"\\nüîç MODEL INSIGHTS:\")\n",
    "    \n",
    "    # Direction bias\n",
    "    if mean_error > 0:\n",
    "        bias_direction = \"over-predicting\"\n",
    "        bias_emoji = \"üìà\"\n",
    "    elif mean_error < 0:\n",
    "        bias_direction = \"under-predicting\" \n",
    "        bias_emoji = \"üìâ\"\n",
    "    else:\n",
    "        bias_direction = \"unbiased\"\n",
    "        bias_emoji = \"‚öñÔ∏è\"\n",
    "    \n",
    "    print(f\"   {bias_emoji} Prediction Bias: Model is {bias_direction} by {abs(mean_error):,.2f} on average\")\n",
    "    \n",
    "    # Consistency\n",
    "    consistency_pct = (error_std / actual_values.mean()) * 100\n",
    "    if consistency_pct < 5:\n",
    "        consistency = \"Very Consistent\"\n",
    "        consistency_emoji = \"üü¢\"\n",
    "    elif consistency_pct < 10:\n",
    "        consistency = \"Consistent\"\n",
    "        consistency_emoji = \"üü°\"\n",
    "    else:\n",
    "        consistency = \"Variable\"\n",
    "        consistency_emoji = \"üü†\"\n",
    "    \n",
    "    print(f\"   {consistency_emoji} Prediction Consistency: {consistency} (Error std: {consistency_pct:.2f}% of mean)\")\n",
    "    \n",
    "    # Accuracy assessment\n",
    "    if mape < 5:\n",
    "        accuracy_level = \"Excellent accuracy for business use\"\n",
    "        accuracy_emoji = \"üü¢\"\n",
    "    elif mape < 10:\n",
    "        accuracy_level = \"Good accuracy for most applications\"\n",
    "        accuracy_emoji = \"üü°\"\n",
    "    elif mape < 20:\n",
    "        accuracy_level = \"Fair accuracy, consider improvements\"\n",
    "        accuracy_emoji = \"üü†\"\n",
    "    else:\n",
    "        accuracy_level = \"Poor accuracy, model needs improvement\"\n",
    "        accuracy_emoji = \"üî¥\"\n",
    "    \n",
    "    print(f\"   {accuracy_emoji} Business Utility: {accuracy_level}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ RECOMMENDATIONS:\")\n",
    "    print(\"   1. Monitor model performance on new data\")\n",
    "    print(\"   2. Retrain model when MAPE exceeds acceptable threshold\")\n",
    "    print(\"   3. Consider ensemble methods if single model accuracy is insufficient\")\n",
    "    print(\"   4. Implement real-time error tracking for production deployment\")\n",
    "    print(\"   5. Set up alerts for predictions outside confidence intervals\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Section 8 completed successfully!\")\n",
    "    print(\"üéâ Forecast vs Actual comparison analysis finished!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå SECTION 8 INCOMPLETE\")\n",
    "    print(\"Some components of the forecast vs actual analysis could not be completed.\")\n",
    "    print(\"Please check previous cells for any errors and ensure all data is available.\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
